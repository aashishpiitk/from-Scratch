{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16_fine_tune_last_three_layers.ipynb",
      "provenance": [],
      "mount_file_id": "1HDwsCZcpo5L-DUuh1n5O2Dqo_de4uJJm",
      "authorship_tag": "ABX9TyPgMsQLPZDSdbRvXyFqDVoB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b917693278a47569b09ba9bd6c2aa00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ef6bb88931a4ee0bfb6c07b495aa1c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd9a3ed20b9d4b669b0914d36c226467",
              "IPY_MODEL_8133f99f2f4943329f5de6f4d3488aa8"
            ]
          }
        },
        "3ef6bb88931a4ee0bfb6c07b495aa1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd9a3ed20b9d4b669b0914d36c226467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c77407e0fda548ffbbd207ddae8a5343",
            "_dom_classes": [],
            "description": "Training Epoch 0 :   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 3000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b977b0d6043a43daac55663d828646e9"
          }
        },
        "8133f99f2f4943329f5de6f4d3488aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdf9011d29be4e94961ff7082c2eab7b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3000 [00:31&lt;7:36:58,  9.15s/it, acc=0, loss=2.78]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcca26704c88421fb536f3abf8b1232a"
          }
        },
        "c77407e0fda548ffbbd207ddae8a5343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b977b0d6043a43daac55663d828646e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdf9011d29be4e94961ff7082c2eab7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcca26704c88421fb536f3abf8b1232a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashishpiitkEigenlytics/Super-Resolution/blob/main/vgg16_fine_tune_last_three_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ka4JCmVEA7u"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, math, sys\n",
        "import glob, itertools\n",
        "import argparse, random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import vgg19\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random.seed(42)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import math\n",
        "from pathlib import Path\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-N0xePgwNUW"
      },
      "source": [
        "# number of epochs of training\n",
        "n_epochs = 50\n",
        "# name of the dataset\n",
        "dataset_path = \"/content/train/test/\"\n",
        "# size of the batches\n",
        "batch_size = 2\n",
        "# adam: learning rate\n",
        "lr = 0.00008\n",
        "# adam: decay of first order momentum of gradient\n",
        "b1 = 0.5\n",
        "# adam: decay of second order momentum of gradient\n",
        "b2 = 0.999\n",
        "# epoch from which to start lr decay\n",
        "decay_epoch = 100\n",
        "# number of cpu threads to use during batch generation\n",
        "n_cpu = 8\n",
        "# high res. image height\n",
        "hr_height = 64\n",
        "# high res. image width\n",
        "hr_width = 64\n",
        "# number of image channels\n",
        "channels = 1\n",
        "\n",
        "# os.makedirs(\"images\", exist_ok=True)\n",
        "# os.makedirs(\"saved_models\", exist_ok=True)\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "hr_shape = (hr_height, hr_width)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO19iCltcdYr"
      },
      "source": [
        "! rm -r /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_p8HemOEnJR"
      },
      "source": [
        "! unzip -q /content/drive/MyDrive/rvl_cdip_test_dataset/rvl_cdip_test_dataset.zip -d /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq2_wMvwuO8n"
      },
      "source": [
        "doc2label = {\n",
        "    'advertisement':0,\n",
        "    'budget':1,\n",
        "    'email':2,\n",
        "    'file_folder':3,\n",
        "    'form':4,\n",
        "    'handwritten':5,\n",
        "    'invoice':6,\n",
        "    'letter':7,\n",
        "    'memo':8,\n",
        "    'news_article':9,\n",
        "    'presentation':10,\n",
        "    'questionnaire':11,\n",
        "    'resume':12,\n",
        "    'scientific_publication':13,\n",
        "    'scientific_report':14,\n",
        "    'specification':15\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmaqFRZJhbZs"
      },
      "source": [
        "train_path = []\n",
        "for path in Path('/content/train/content/train/test').rglob('*.tif'):\n",
        "  target = str(str(path).split('/')[-2])\n",
        "  train_path.append((path, doc2label[target]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkr4cd-1wkMp"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, files):\n",
        "    #super(ImageDataset, self)\n",
        "\n",
        "    self.files = files\n",
        "    self.trans = transforms.Compose([\n",
        "                                transforms.Grayscale(),\n",
        "                                transforms.Resize((780,600)), \n",
        "                                transforms.ToTensor()\n",
        "    ])\n",
        "    self.trans2 = transforms.Resize((227,227))\n",
        "\n",
        "    #self.trans1 = transforms.ToTensor()\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.files[index % len(self.files)][0])\n",
        "    target = self.files[index % len(self.files)][1]\n",
        "    \n",
        "    output_dict = {\n",
        "        'targets' : torch.tensor(target),\n",
        "        'holistic' : self.create_holistic(img),\n",
        "    }\n",
        "\n",
        "    return output_dict\n",
        "  \n",
        "  def create_header(self, x):\n",
        "    # trans1 = transforms.ToTensor()\n",
        "    x = self.trans(x)\n",
        "\n",
        "    x = x[:][:, :, :256]\n",
        "    return self.trans2(x)\n",
        "\n",
        "\n",
        "  def create_right_half(self, x):\n",
        "    x = self.trans(x)\n",
        "\n",
        "    x = x[:][:, -300:, 100:-100]\n",
        "    return self.trans2(x)\n",
        "  def create_left_half(self, x):\n",
        "    x = self.trans(x)\n",
        "\n",
        "    x = x[:][:, :300, 100:-100]\n",
        "    return self.trans2(x)\n",
        "  def create_footer(self, x):\n",
        "    x = self.trans(x)\n",
        "\n",
        "    x = x[:][:, :, -256:]\n",
        "    return self.trans2(x)\n",
        "\n",
        "  def create_holistic(self, x):\n",
        "    \n",
        "    return self.trans(x)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.files)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hIVq4noQz5f"
      },
      "source": [
        "# train_path = train_path[:len(train_path)//5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpdAhjNJ3Fjm",
        "outputId": "d023cfac-2f2b-4577-f70b-5b13dd5226a4"
      },
      "source": [
        "len(train_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XBEQUJFMdMt"
      },
      "source": [
        "## incorporate the labels somehow when preparing the dataset usign ImageDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyyzMFxB0w6V"
      },
      "source": [
        "train_paths, test_paths = train_test_split(train_path, test_size=0.1)\n",
        "train_paths = train_paths[:len(train_paths)//6]\n",
        "test_paths = test_paths[:len(test_paths)//6]\n",
        "\n",
        "#train_paths, test_paths = train_test_split(sorted(glob.glob(dataset_path + \"/*.*\")), test_size=0.02, random_state=42)\n",
        "train_dataloader = DataLoader(ImageDataset(train_paths), batch_size=batch_size, shuffle=True, num_workers=n_cpu)\n",
        "test_dataloader = DataLoader(ImageDataset(test_paths), batch_size=int(batch_size), shuffle=True, num_workers=n_cpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glyzIZDt3HjM",
        "outputId": "69b84ac0-7d37-497b-e87e-7012962c83aa"
      },
      "source": [
        "len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEZxRnk3dwNi",
        "outputId": "af1f594c-7d63-41f9-df86-3baaffb40877"
      },
      "source": [
        "len(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Ae-lKwfyId"
      },
      "source": [
        "class VGG16_fine_tune_last_three_layer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG16_fine_tune_last_three_layer, self).__init__()\n",
        "\n",
        "    vgg16_model = torchvision.models.vgg16(pretrained = True)\n",
        "    self.feature_extractor = nn.Sequential(*list(vgg16_model.features.children()))\n",
        "    self.avg_pool = vgg16_model.avgpool#nn.Sequential(*list(vgg16_model.avgpool.children()))\n",
        "    #self.classifier = nn.Sequential(*list(vgg16_model.classifier.children())[:-])\n",
        "\n",
        "    for name, param in self.feature_extractor.named_parameters():\n",
        "      param.requires_grad = False\n",
        "    for name, param in self.avg_pool.named_parameters():\n",
        "      param.requires_grad = False\n",
        "    # for name, param in self.classifier.named_parameters():\n",
        "    #   param.requires_grad = False\n",
        "\n",
        "    self.last_three_layers = nn.Sequential(nn.Linear(25088, 4096, bias=True),\n",
        "                                           nn.ReLU(inplace=True),\n",
        "                                           nn.Dropout(p=0.5, inplace=False),\n",
        "                                           nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
        "                                           nn.ReLU(inplace=True),\n",
        "                                           nn.Dropout(p=0.5, inplace=False),\n",
        "                                           nn.Linear(in_features=4096, out_features=16, bias=True)\n",
        "                                           )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.avg_pool(x)\n",
        "    #x = self.classifier(torch.flatten(x, start_dim=1))\n",
        "    \n",
        "    output = self.last_three_layers(torch.flatten(x, start_dim=1))\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok_eKuMCtOAv"
      },
      "source": [
        "vgg16_fine_tune_last_three_layer = VGG16_fine_tune_last_three_layer().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uykWFdc1ABjr",
        "outputId": "b977633c-04ee-4f5c-c056-f54574e24bbf"
      },
      "source": [
        "for name, param in vgg16_fine_tune_last_three_layer.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last_three_layers.0.weight\n",
            "last_three_layers.0.bias\n",
            "last_three_layers.3.weight\n",
            "last_three_layers.3.bias\n",
            "last_three_layers.6.weight\n",
            "last_three_layers.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThwvgOfhtjTc"
      },
      "source": [
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, vgg16_fine_tune_last_three_layer.parameters()), \n",
        "                             lr=lr, betas=(b1, b2))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGPhnekZZ5Y1"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8oGs8coaJoD"
      },
      "source": [
        "# ## loading the weights\n",
        "# checkpoint = torch.load(\"/content/drive/MyDrive/vgg16_last_layer_fine_tune_rvl_cdip_checkpt16.pt\",map_location=torch.device(device))\n",
        "\n",
        "# vgg16_fine_tune_last_layer.load_state_dict(checkpoint['vgg16_fine_tune_last_layer'])\n",
        "# # vgg16_fine_tune_last_layer.load_state_dict()\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# vgg16_fine_tune_last_layer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywchf_PsxWl5",
        "outputId": "a8b3ee41-5ec5-409a-eb3a-921af1b0ecde"
      },
      "source": [
        "for param_tensor in vgg16_fine_tune_last_three_layer.state_dict():\n",
        "  print(param_tensor, \"\\t\", vgg16_fine_tune_last_three_layer.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature_extractor.0.weight \t torch.Size([64, 3, 3, 3])\n",
            "feature_extractor.0.bias \t torch.Size([64])\n",
            "feature_extractor.2.weight \t torch.Size([64, 64, 3, 3])\n",
            "feature_extractor.2.bias \t torch.Size([64])\n",
            "feature_extractor.5.weight \t torch.Size([128, 64, 3, 3])\n",
            "feature_extractor.5.bias \t torch.Size([128])\n",
            "feature_extractor.7.weight \t torch.Size([128, 128, 3, 3])\n",
            "feature_extractor.7.bias \t torch.Size([128])\n",
            "feature_extractor.10.weight \t torch.Size([256, 128, 3, 3])\n",
            "feature_extractor.10.bias \t torch.Size([256])\n",
            "feature_extractor.12.weight \t torch.Size([256, 256, 3, 3])\n",
            "feature_extractor.12.bias \t torch.Size([256])\n",
            "feature_extractor.14.weight \t torch.Size([256, 256, 3, 3])\n",
            "feature_extractor.14.bias \t torch.Size([256])\n",
            "feature_extractor.17.weight \t torch.Size([512, 256, 3, 3])\n",
            "feature_extractor.17.bias \t torch.Size([512])\n",
            "feature_extractor.19.weight \t torch.Size([512, 512, 3, 3])\n",
            "feature_extractor.19.bias \t torch.Size([512])\n",
            "feature_extractor.21.weight \t torch.Size([512, 512, 3, 3])\n",
            "feature_extractor.21.bias \t torch.Size([512])\n",
            "feature_extractor.24.weight \t torch.Size([512, 512, 3, 3])\n",
            "feature_extractor.24.bias \t torch.Size([512])\n",
            "feature_extractor.26.weight \t torch.Size([512, 512, 3, 3])\n",
            "feature_extractor.26.bias \t torch.Size([512])\n",
            "feature_extractor.28.weight \t torch.Size([512, 512, 3, 3])\n",
            "feature_extractor.28.bias \t torch.Size([512])\n",
            "last_three_layers.0.weight \t torch.Size([4096, 25088])\n",
            "last_three_layers.0.bias \t torch.Size([4096])\n",
            "last_three_layers.3.weight \t torch.Size([4096, 4096])\n",
            "last_three_layers.3.bias \t torch.Size([4096])\n",
            "last_three_layers.6.weight \t torch.Size([16, 4096])\n",
            "last_three_layers.6.bias \t torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5W6CnM4yjWT"
      },
      "source": [
        "# # save only model.state_dict()['last_layer.weight'] and model.state_dict()['last_layer.bias']\n",
        "# new_state_dict = {}\n",
        "# layers = ['last_layer.weight', 'last_layer.bias']\n",
        "# for layer in layers:\n",
        "#   print(vgg16_fine_tune_last_layer.state_dict()[layer].shape)\n",
        "#   new_state_dict[layer] = vgg16_fine_tune_last_layer.state_dict()[layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyiH15Uz53ll"
      },
      "source": [
        "# for param_tensor in new_state_dict:\n",
        "#   print(param_tensor, \"\\t\", new_state_dict[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaEuGV8_7dqy",
        "outputId": "0ac9d73f-adfc-4c23-c302-f04abe75c520"
      },
      "source": [
        "## loading the weights\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/vgg16_last_layer_fine_tune_rvl_cdip/checkpt18.pt\",map_location=torch.device(device))\n",
        "\n",
        "new_state_dict = checkpoint['new_state_dict']\n",
        "old_dict = vgg16_fine_tune_last_three_layer.state_dict()\n",
        "old_dict['last_three_layers.6.weight'] = new_state_dict['last_layer.weight']\n",
        "old_dict['last_three_layers.6.bias'] = new_state_dict['last_layer.bias']\n",
        "vgg16_fine_tune_last_three_layer.load_state_dict(old_dict)\n",
        "\n",
        "\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "vgg16_fine_tune_last_three_layer.train()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16_fine_tune_last_three_layer(\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avg_pool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (last_three_layers): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=16, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6qba5XJ6Oc9"
      },
      "source": [
        "## we will save and load this dictionary only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozk7oJn03QVJ"
      },
      "source": [
        "def accuracy(x, targets):\n",
        "  # receive the outputs of linear layer\n",
        "  # first apply softmax then take argmax to know the index\n",
        "  # then compare\n",
        "  # input will be (batch_size, )\n",
        "  probs = nn.functional.softmax(x)\n",
        "  labels = torch.argmax(probs, dim=1)\n",
        "\n",
        "  count=0\n",
        "  for label, target in zip(labels, targets):\n",
        "    #print(label, target)\n",
        "    if(label.item() == target.item()):\n",
        "      count+=1\n",
        "  \n",
        "  return count/labels.shape[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97S8TtiXPdmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "9b917693278a47569b09ba9bd6c2aa00",
            "3ef6bb88931a4ee0bfb6c07b495aa1c7",
            "cd9a3ed20b9d4b669b0914d36c226467",
            "8133f99f2f4943329f5de6f4d3488aa8",
            "c77407e0fda548ffbbd207ddae8a5343",
            "b977b0d6043a43daac55663d828646e9",
            "cdf9011d29be4e94961ff7082c2eab7b",
            "bcca26704c88421fb536f3abf8b1232a"
          ]
        },
        "outputId": "8adbaa0d-2ee4-47aa-fe1a-a2b98b191850"
      },
      "source": [
        "train_losses, test_losses = [], []\n",
        "train_acc, test_acc = [], []\n",
        "test_counter = [idx*len(test_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "train_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  ## Training loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(train_dataloader, desc=f'Training Epoch {epoch} ', total=int(len(train_dataloader)))\n",
        "\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    vgg16_fine_tune_last_three_layer.train();\n",
        "\n",
        "    for key in imgs:\n",
        "      imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic']\n",
        "    targets = imgs['targets']\n",
        "\n",
        "\n",
        "    ## convert the 1 channel image to 3 channel image\n",
        "    holistic_img_3 = holistic_img.repeat_interleave(3, dim=1)\n",
        "    holistic_img_3[:, 1:3, :, :] = 0\n",
        "\n",
        "    prediction = vgg16_fine_tune_last_three_layer(holistic_img_3.to(device))\n",
        "\n",
        "    loss_calc = criterion(prediction.to(device), targets.to(device))\n",
        "\n",
        "    loss_calc.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(prediction.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  train_losses.append(loss/len(train_dataloader)) ## divided by total number of batches\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  ## Testing loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n",
        "\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "\n",
        "    vgg16_fine_tune_last_three_layer.eval();\n",
        "    \n",
        "    for key in imgs:\n",
        "      imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic']\n",
        "    targets = imgs['targets']\n",
        "    \n",
        "    ## convert the 1 channel image to 3 channel image\n",
        "    holistic_img_3 = holistic_img.repeat_interleave(3, dim=1)\n",
        "    holistic_img_3[:, 1:3, :, :] = 0\n",
        "    \n",
        "    prediction = vgg16_fine_tune_last_three_layer(holistic_img_3.to(device))\n",
        "\n",
        "    loss_calc = criterion(prediction.to(device), targets.to(device))\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(prediction.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  test_losses.append(loss/len(test_dataloader)) ## divided by total number of batches\n",
        "\n",
        "\n",
        "  new_state_dict = {}\n",
        "  layers = ['last_three_layers.6.bias', 'last_three_layers.6.weight', 'last_three_layers.3.bias', 'last_three_layers.3.bias', 'last_three_layers.0.bias', 'last_three_layers.0.bias']\n",
        "  for layer in layers:\n",
        "    #print(vgg16_fine_tune_last_layer.state_dict()[layer].shape)\n",
        "    new_state_dict[layer] = vgg16_fine_tune_last_layer.state_dict()[layer]\n",
        "\n",
        "  if(True):\n",
        "    torch.save({\n",
        "          \n",
        "          'new_state_dict' : new_state_dict,\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'train_loss' : train_losses[-1],\n",
        "          'test_loss' : test_losses[-1],\n",
        "          'epoch': epoch+1,\n",
        "          }, f\"/content/drive/MyDrive/vgg16_fine_tune_last_three_layers/checkpt{epoch+1}.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b917693278a47569b09ba9bd6c2aa00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 0 ', max=3000.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-ab14fb7cf3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mholistic_img_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16_fine_tune_last_three_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholistic_img_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mloss_calc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-3a0052cc9012>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#x = self.classifier(torch.flatten(x, start_dim=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccwvcjDHPaG5",
        "outputId": "057c2d5b-0ac2-492c-9a32-b224b47f02e3"
      },
      "source": [
        "out = nn.functional.softmax(torch.randn(4,10), dim=1)\n",
        "print(out.shape, torch.argmax(out, dim=1).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 10]) torch.Size([4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Q86JLkYKCJ",
        "outputId": "05934841-8753-4548-a8f6-662cb66c1da9"
      },
      "source": [
        "for i, j in zip(range(5), range(3)):\n",
        "  print(i,j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "1 1\n",
            "2 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1oonPnZedV7",
        "outputId": "3bd8fa98-8b20-4db7-ff54-3ab10eaa376e"
      },
      "source": [
        "torch.tensor([1,2,3]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFt-d7hpc9_6",
        "outputId": "a06fffd5-c756-4a5d-e98a-efc226901bf2"
      },
      "source": [
        "print(accuracy(torch.randn(6, 16).to(device), torch.tensor([1,2,3,4,5,6]).to(device)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(11, device='cuda:0') tensor(1, device='cuda:0')\n",
            "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
            "tensor(9, device='cuda:0') tensor(3, device='cuda:0')\n",
            "tensor(6, device='cuda:0') tensor(4, device='cuda:0')\n",
            "tensor(6, device='cuda:0') tensor(5, device='cuda:0')\n",
            "tensor(1, device='cuda:0') tensor(6, device='cuda:0')\n",
            "0.16666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZjTOWbbIOTN"
      },
      "source": [
        "# vgg16 = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK7tnyOXjDRI"
      },
      "source": [
        "# modify the last layer to give output to 16 classes\n",
        "# no need to attach softmax at last as cross entropy loss automatically takes care of that in pytorch by appling softmax automatically"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pT0UGxxmCPA"
      },
      "source": [
        "# one way is to delete the last layer and then add a new layer with the required specification\n",
        "# second way is to modify the layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85TmXalHlPUC"
      },
      "source": [
        "# temp = nn.Conv2d(2,64,3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Mouyq-ogkb"
      },
      "source": [
        "# print(temp.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a8EhCi3olFc"
      },
      "source": [
        "# for parameter in temp.parameters():\n",
        "#   print(parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4qsngLHov2o"
      },
      "source": [
        "# print(temp.in_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgGomgR-o20w"
      },
      "source": [
        "# temp.in_channels = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlboHWLLo5t8"
      },
      "source": [
        "# print(temp.in_channels, temp.out_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ath0fEP1prkt"
      },
      "source": [
        "# for child_counter, child in enumerate(vgg16.children()):\n",
        "#   print(\"child\", child_counter, \"is -\")\n",
        "#   print(child)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpBXa8dyo9P6"
      },
      "source": [
        "# for child_index, child in enumerate(vgg16.children()):\n",
        "#   if(child_index == 2):\n",
        "#     for sub_child_index, sub_child in enumerate(child.children()):\n",
        "#       if(sub_child_index == 6):\n",
        "#         sub_child.out_features = 16\n",
        "#   # if(child_index == 0):\n",
        "#   #   for sub_child_index, sub_child in enumerate(child.children()):\n",
        "#   #     if(sub_child_index == 0):\n",
        "#   #       sub_child.in_channels = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W88ZEqoqdMH"
      },
      "source": [
        "# for child_counter, child in enumerate(vgg16.children()):\n",
        "#   print(\"child\", child_counter, \"is -\")\n",
        "#   print(child)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc0ahjAkkN2T"
      },
      "source": [
        "# freeze all the layers except the last fully connected layer for first experiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJWZTeaFqfmo"
      },
      "source": [
        "# for child_index, child in enumerate(vgg16.children()):\n",
        "#   for sub_child_index, sub_child in enumerate(child.children()):\n",
        "#     if(not((sub_child_index == 6) and (child_index == 2))):\n",
        "#       for parameter in sub_child.parameters():\n",
        "#         parameter.requires_grad = False\n",
        "#     else:\n",
        "#       for parameter in sub_child.parameters():\n",
        "#         parameter.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-20wkLtDx7"
      },
      "source": [
        "# # check if the requries_grad is false for the requrid layers\n",
        "# for child_index, child in enumerate(vgg16.children()):\n",
        "#   for sub_child_index, sub_child in enumerate(child.children()):\n",
        "#     if(not((sub_child_index == 6) and (child_index == 2))):\n",
        "#       for parameter in sub_child.parameters():\n",
        "#         print(sub_child, parameter.requires_grad)\n",
        "#     else:\n",
        "#       for parameter in sub_child.parameters():\n",
        "#         print(sub_child, parameter.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbVhQpmlLAl"
      },
      "source": [
        "# initialize the optimizer carefully as you have frozen some of the layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYIzvEUmwEJx"
      },
      "source": [
        "# now we are ready to train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5H5X8wVxYLt"
      },
      "source": [
        "## prepare the data with labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-tgVZr7fhH7"
      },
      "source": [
        "## using the module concept\n",
        "# first delete the last layer\n",
        "# then add a linear layer by using a nn.Module class\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkXNmBOXoQ5X"
      },
      "source": [
        "# vgg16.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFB05ll8yXmg"
      },
      "source": [
        "# print(vgg16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC9j2akxpeYJ"
      },
      "source": [
        "# vgg16.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIZwgIxMrXHu"
      },
      "source": [
        "# layers = []\n",
        "# for child_counter, child in enumerate(vgg16.children()):\n",
        "#   if(child_counter<2): \n",
        "#     layers.append(child)\n",
        "#   else:\n",
        "#     layers.append(nn.Sequential(*list(child.children())[:-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA3QAf_Xrbp9"
      },
      "source": [
        "# print(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hap7WsBn7ks3"
      },
      "source": [
        "# feature_extractor = nn.Sequential(*list(vgg16.features.children()))\n",
        "# print(feature_extractor(torch.randn(4,3,512,512)).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5bM__y7yfc"
      },
      "source": [
        "# avg_pool = vgg16.avgpool#nn.Sequential(*list(vgg16.avgpool.children()))\n",
        "# print(avg_pool(torch.randn(4,512,16,16)).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whnbakex9dug"
      },
      "source": [
        "# print(torch.flatten(torch.randn(4,512,7,7)).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG-bq-cu79CW"
      },
      "source": [
        "# classifier = nn.Sequential(*list(vgg16.classifier.children()))\n",
        "# print(classifier(torch.flatten(torch.randn(4,512,7,7), start_dim=1)).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okXBFdvFHb3A"
      },
      "source": [
        "# del vgg16_fine_tune_last_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uPSU7NwIYCA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0f_AQm1AKrv"
      },
      "source": [
        "## Hence it is verified that only the last layer is trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfr540FaxbMS"
      },
      "source": [
        "#################################################\n",
        "##################################################\n",
        "################################################################\n",
        "#####################################################################\n",
        "############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huxk7i-YP1qy"
      },
      "source": [
        "# ! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DDjGKEfR5Cp"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUZONV7AFH2o"
      },
      "source": [
        "# % ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9OLsb-j8kbX"
      },
      "source": [
        "# % mkdir ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dfUz-ht8uvK"
      },
      "source": [
        "# ! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyaEi1ESSe8p"
      },
      "source": [
        "# ! kaggle datasets download -d pdavpoojan/the-rvlcdip-dataset-test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjMvUfC-909z"
      },
      "source": [
        "# ! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOupjoGoSzH3"
      },
      "source": [
        "# % mkdir train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIoCO6xRruo6"
      },
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ8V9v6kVe3_"
      },
      "source": [
        "## to delete the whole directory\n",
        "##import shutil\n",
        "##shutil.rmtree('/content/kaggle/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEHVvLxzWFKs"
      },
      "source": [
        "# ! unzip -q /content/the-rvlcdip-dataset-test.zip -d /content/train "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ1bKmFGEzxS"
      },
      "source": [
        "# ## to remove the curropted files\n",
        "# import cv2\n",
        "# for dirname, _, filenames in os.walk(\"/content/train/test/\"):\n",
        "#     for filename in filenames:\n",
        "#         if not hasattr(cv2.imread(os.path.join(dirname, filename)), \"shape\"):\n",
        "#             os.remove(os.path.join(dirname,filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIHfwYWyBCjc"
      },
      "source": [
        "# ! zip -q -r /content/drive/MyDrive/rvl_cdip_test_dataset/rvl_cdip_test_dataset.zip /content/train/test/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G5OZJ-DId_V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxOg4IYRj8g-"
      },
      "source": [
        "# for file in train_path:\n",
        "#   print(file[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6uLS9-euL49"
      },
      "source": [
        "# trans1 = transforms.ToTensor()\n",
        "# print(torch.tensor(8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6VqA8T7IiKJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL_-noNw1c8v"
      },
      "source": [
        "# iterator = iter(train_dataloader)\n",
        "# batch = next(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcvyIWupFgPe"
      },
      "source": [
        "# print(batch['holistic'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYUwy2Ye2u3M"
      },
      "source": [
        "# print(iterator.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q00Om0jK3_14"
      },
      "source": [
        "# # check if the requries_grad is false for the requrid layers\n",
        "# for child_index, child in enumerate(vgg16.to(device).children()):\n",
        "#   for sub_child_index, sub_child in enumerate(child.children()):\n",
        "#     if(not((sub_child_index == 6) and (child_index == 2))):\n",
        "#       for parameter in sub_child.parameters():\n",
        "#         print(sub_child, parameter.requires_grad)\n",
        "#     else:\n",
        "#       for parameter in sub_child.parameters():\n",
        "#         print(sub_child, parameter.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbbfPsxdjK_J"
      },
      "source": [
        "# output = vgg16(torch.randn(1,3,512,512))\n",
        "# print(output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okr_bTUI35Eu"
      },
      "source": [
        "# summary(vgg16.to(device), (3,512,512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL6Px8SyI0h8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}