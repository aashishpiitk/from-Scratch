{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18_ensemble_custom_image_testing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4H9QbbRjyRDwEpTyAPqSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashishpiitkEigenlytics/document_classification_/blob/main/resnet18_ensemble_custom_image_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbDj15v4q-dM",
        "outputId": "fcdd2efa-22d7-4342-f3f9-4cde9d1927cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ka4JCmVEA7u"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, math, sys\n",
        "import glob, itertools\n",
        "import argparse, random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import vgg19\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random.seed(42)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import math\n",
        "from pathlib import Path\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-N0xePgwNUW"
      },
      "source": [
        "# number of epochs of training\n",
        "n_epochs = 50\n",
        "# name of the dataset\n",
        "dataset_path = \"/content/train/test/\"\n",
        "# size of the batches\n",
        "batch_size = 16\n",
        "# adam: learning rate\n",
        "lr = 0.00008\n",
        "# adam: decay of first order momentum of gradient\n",
        "b1 = 0.5\n",
        "# adam: decay of second order momentum of gradient\n",
        "b2 = 0.999\n",
        "# epoch from which to start lr decay\n",
        "decay_epoch = 100\n",
        "# number of cpu threads to use during batch generation\n",
        "n_cpu = 8\n",
        "# high res. image height\n",
        "hr_height = 64\n",
        "# high res. image width\n",
        "hr_width = 64\n",
        "# number of image channels\n",
        "channels = 1\n",
        "\n",
        "# os.makedirs(\"images\", exist_ok=True)\n",
        "# os.makedirs(\"saved_models\", exist_ok=True)\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "hr_shape = (hr_height, hr_width)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_p8HemOEnJR"
      },
      "source": [
        "! unzip -q /content/drive/MyDrive/rvl_cdip_test_dataset/rvl_cdip_test_dataset.zip -d /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq2_wMvwuO8n"
      },
      "source": [
        "doc2label = {\n",
        "    'advertisement':0,\n",
        "    'budget':1,\n",
        "    'email':2,\n",
        "    'file_folder':3,\n",
        "    'form':4,\n",
        "    'handwritten':5,\n",
        "    'invoice':6,\n",
        "    'letter':7,\n",
        "    'memo':8,\n",
        "    'news_article':9,\n",
        "    'presentation':10,\n",
        "    'questionnaire':11,\n",
        "    'resume':12,\n",
        "    'scientific_publication':13,\n",
        "    'scientific_report':14,\n",
        "    'specification':15\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmaqFRZJhbZs"
      },
      "source": [
        "train_path = []\n",
        "for path in Path('/content/custom_data').rglob('*.jpg'):\n",
        "  target = str(str(path).split('/')[-2])\n",
        "  train_path.append((path, doc2label[target]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkr4cd-1wkMp"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, files):\n",
        "    #super(ImageDataset, self)\n",
        "\n",
        "    self.files = files\n",
        "    self.trans = transforms.Compose([\n",
        "                                transforms.Grayscale(),\n",
        "                                transforms.Resize((780,600)), \n",
        "                                transforms.ToTensor(),\n",
        "                                \n",
        "    ])\n",
        "    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225])\n",
        "    \n",
        "    self.trans2 = transforms.Resize((227,227))\n",
        "\n",
        "    #self.trans1 = transforms.ToTensor()\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.files[index % len(self.files)][0])\n",
        "    target = self.files[index % len(self.files)][1]\n",
        "    \n",
        "    output_dict = {\n",
        "        'targets' : torch.tensor(target),\n",
        "        'right' : self.create_right_half(img),\n",
        "        'left' : self.create_left_half(img),\n",
        "        ''\n",
        "    }\n",
        "\n",
        "    return output_dict\n",
        "  \n",
        "  def create_header(self, x):\n",
        "    # trans1 = transforms.ToTensor()\n",
        "    x = self.trans(x)\n",
        "    x = x.repeat_interleave(3, dim=0)\n",
        "    x=self.normalize(x)\n",
        "    x = x[:][:, :256, :]\n",
        "    return self.trans2(x)\n",
        "\n",
        "\n",
        "  def create_right_half(self, x):\n",
        "    x = self.trans(x)\n",
        "    x = x.repeat_interleave(3, dim=0)\n",
        "    x=self.normalize(x)\n",
        "    \n",
        "    x = x[:][:, 100:-100, -300:]\n",
        "    return self.trans2(x)\n",
        "  def create_left_half(self, x):\n",
        "    x = self.trans(x)\n",
        "\n",
        "    x = x[:][:, 100:-100, :300]\n",
        "    return self.trans2(x)\n",
        "\n",
        "  def create_footer(self, x):\n",
        "    x = self.trans(x)\n",
        "    x = x.repeat_interleave(3, dim=0)\n",
        "    x=self.normalize(x)\n",
        "    x = x[:][:, -256:, :]\n",
        "    return self.trans2(x)\n",
        "\n",
        "  def create_holistic(self, x):\n",
        "    x = self.trans(x)\n",
        "    #print(x.shape)  (channels, h, w) not batch_size in dimensions\n",
        "    x = x.repeat_interleave(3, dim=0)\n",
        "    return self.normalize(x)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.files)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hIVq4noQz5f"
      },
      "source": [
        "# train_path = train_path[:len(train_path)//5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpdAhjNJ3Fjm",
        "outputId": "4fa6a280-8d7c-441c-a325-8896cbac9f0c"
      },
      "source": [
        "len(train_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XBEQUJFMdMt"
      },
      "source": [
        "## incorporate the labels somehow when preparing the dataset usign ImageDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyyzMFxB0w6V"
      },
      "source": [
        "train_paths, test_paths = train_test_split(train_path, test_size=0.15, random_state=42)\n",
        "train_paths = train_paths[:len(train_paths)]\n",
        "test_paths = test_paths[:len(test_paths)]\n",
        "\n",
        "#train_paths, test_paths = train_test_split(sorted(glob.glob(dataset_path + \"/*.*\")), test_size=0.02, random_state=42)\n",
        "train_dataloader = DataLoader(ImageDataset(train_paths), batch_size=batch_size, shuffle=True, num_workers=n_cpu)\n",
        "test_dataloader = DataLoader(ImageDataset(test_paths), batch_size=int(batch_size), shuffle=True, num_workers=n_cpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glyzIZDt3HjM",
        "outputId": "e6a3866e-be53-4f9e-9f09-c719bcd1d3e2"
      },
      "source": [
        "len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJEWdhXQTuaV",
        "outputId": "850a67c9-b6f1-4cb9-b251-192020395e80"
      },
      "source": [
        "print(len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMvAKM8IzRu_"
      },
      "source": [
        "# resnet18 = torchvision.models.resnet18(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrPXu-ZpzXma"
      },
      "source": [
        "# print(resnet18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSdVJ6ps0i6L"
      },
      "source": [
        "# resent18.children()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5FAdP506ml"
      },
      "source": [
        "# for child_counter, child in enumerate(resnet18.children()):\n",
        "#   print(child)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKNw5S1p28sD"
      },
      "source": [
        "# for name, param in list(resnet18.named_parameters())[:-17]:\n",
        "#       print(name, param.shape, param.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsLPQN0C5Zwu"
      },
      "source": [
        "# feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "# print(feature_extractor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Ae-lKwfyId"
      },
      "source": [
        "class ResNet18_fine_tune(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResNet18_fine_tune, self).__init__()\n",
        "\n",
        "    self.resnet18_model = torchvision.models.resnet18(pretrained=True)\n",
        "    self.feature_extractor = nn.Sequential(*list(self.resnet18_model.children())[:-1])\n",
        "    \n",
        "    for (name, param) in (list(self.feature_extractor.named_parameters())[:-60]):\n",
        "      param.requires_grad = False\n",
        "    for (name, param) in (list(self.feature_extractor.named_parameters())[-60:]):\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.classifier = nn.Sequential(nn.Linear(512, 128, bias=True),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(128,16, bias=True))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.feature_extractor(x)\n",
        "    \n",
        "    x = self.classifier(torch.flatten(x, start_dim=1))\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "675da514017445d98c8e4d569826f6f6",
            "a77564205bc7461bbfa1e91fc6d28d6e",
            "6637c95700cf497bba41a85b5f0db290",
            "b096c42d0f794bdb99bd40579dbbe667",
            "3f22497a1852407a9f330a668d4c9f13",
            "2b57b7cae57b48f7b0f7b6c5b3fe8d36",
            "81cccbcb70aa4e7186068d5602f52499",
            "29700081f846471390071d83daa79f26"
          ]
        },
        "id": "Ok_eKuMCtOAv",
        "outputId": "271f27a9-62be-40d3-f3ab-158388b4a960"
      },
      "source": [
        "resnet18_fine_tune = ResNet18_fine_tune().to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "675da514017445d98c8e4d569826f6f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKPRh_w9YPsW"
      },
      "source": [
        "# print(resnet18_fine_tune)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL96oDqS-BJT"
      },
      "source": [
        "# output = resnet18_fine_tune(torch.randn(3,3,780,600))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cT0UROI-8YK"
      },
      "source": [
        "# print(output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJYWw3JtTtuN"
      },
      "source": [
        "# print(type(vgg16_fine_tune_last_layer.feature_extractor.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uykWFdc1ABjr",
        "outputId": "d77b9bcd-f8aa-4664-849f-5802be7d4e4e"
      },
      "source": [
        "for name, param in resnet18_fine_tune.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet18_model.conv1.weight\n",
            "resnet18_model.bn1.weight\n",
            "resnet18_model.bn1.bias\n",
            "resnet18_model.layer1.0.conv1.weight\n",
            "resnet18_model.layer1.0.bn1.weight\n",
            "resnet18_model.layer1.0.bn1.bias\n",
            "resnet18_model.layer1.0.conv2.weight\n",
            "resnet18_model.layer1.0.bn2.weight\n",
            "resnet18_model.layer1.0.bn2.bias\n",
            "resnet18_model.layer1.1.conv1.weight\n",
            "resnet18_model.layer1.1.bn1.weight\n",
            "resnet18_model.layer1.1.bn1.bias\n",
            "resnet18_model.layer1.1.conv2.weight\n",
            "resnet18_model.layer1.1.bn2.weight\n",
            "resnet18_model.layer1.1.bn2.bias\n",
            "resnet18_model.layer2.0.conv1.weight\n",
            "resnet18_model.layer2.0.bn1.weight\n",
            "resnet18_model.layer2.0.bn1.bias\n",
            "resnet18_model.layer2.0.conv2.weight\n",
            "resnet18_model.layer2.0.bn2.weight\n",
            "resnet18_model.layer2.0.bn2.bias\n",
            "resnet18_model.layer2.0.downsample.0.weight\n",
            "resnet18_model.layer2.0.downsample.1.weight\n",
            "resnet18_model.layer2.0.downsample.1.bias\n",
            "resnet18_model.layer2.1.conv1.weight\n",
            "resnet18_model.layer2.1.bn1.weight\n",
            "resnet18_model.layer2.1.bn1.bias\n",
            "resnet18_model.layer2.1.conv2.weight\n",
            "resnet18_model.layer2.1.bn2.weight\n",
            "resnet18_model.layer2.1.bn2.bias\n",
            "resnet18_model.layer3.0.conv1.weight\n",
            "resnet18_model.layer3.0.bn1.weight\n",
            "resnet18_model.layer3.0.bn1.bias\n",
            "resnet18_model.layer3.0.conv2.weight\n",
            "resnet18_model.layer3.0.bn2.weight\n",
            "resnet18_model.layer3.0.bn2.bias\n",
            "resnet18_model.layer3.0.downsample.0.weight\n",
            "resnet18_model.layer3.0.downsample.1.weight\n",
            "resnet18_model.layer3.0.downsample.1.bias\n",
            "resnet18_model.layer3.1.conv1.weight\n",
            "resnet18_model.layer3.1.bn1.weight\n",
            "resnet18_model.layer3.1.bn1.bias\n",
            "resnet18_model.layer3.1.conv2.weight\n",
            "resnet18_model.layer3.1.bn2.weight\n",
            "resnet18_model.layer3.1.bn2.bias\n",
            "resnet18_model.layer4.0.conv1.weight\n",
            "resnet18_model.layer4.0.bn1.weight\n",
            "resnet18_model.layer4.0.bn1.bias\n",
            "resnet18_model.layer4.0.conv2.weight\n",
            "resnet18_model.layer4.0.bn2.weight\n",
            "resnet18_model.layer4.0.bn2.bias\n",
            "resnet18_model.layer4.0.downsample.0.weight\n",
            "resnet18_model.layer4.0.downsample.1.weight\n",
            "resnet18_model.layer4.0.downsample.1.bias\n",
            "resnet18_model.layer4.1.conv1.weight\n",
            "resnet18_model.layer4.1.bn1.weight\n",
            "resnet18_model.layer4.1.bn1.bias\n",
            "resnet18_model.layer4.1.conv2.weight\n",
            "resnet18_model.layer4.1.bn2.weight\n",
            "resnet18_model.layer4.1.bn2.bias\n",
            "resnet18_model.fc.weight\n",
            "resnet18_model.fc.bias\n",
            "classifier.0.weight\n",
            "classifier.0.bias\n",
            "classifier.2.weight\n",
            "classifier.2.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGPhnekZZ5Y1"
      },
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8oGs8coaJoD"
      },
      "source": [
        "# ## loading the weights\n",
        "# checkpoint = torch.load(\"/content/drive/MyDrive/vgg16_last_layer_fine_tune_rvl_cdip_checkpt16.pt\",map_location=torch.device(device))\n",
        "\n",
        "# vgg16_fine_tune_last_layer.load_state_dict(checkpoint['vgg16_fine_tune_last_layer'])\n",
        "# # vgg16_fine_tune_last_layer.load_state_dict()\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# vgg16_fine_tune_last_layer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywchf_PsxWl5"
      },
      "source": [
        "# for param_tensor in vgg16_fine_tune_last_layer.state_dict():\n",
        "#   print(param_tensor, \"\\t\", vgg16_fine_tune_last_layer.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5W6CnM4yjWT"
      },
      "source": [
        "# # save only model.state_dict()['last_layer.weight'] and model.state_dict()['last_layer.bias']\n",
        "# new_state_dict = {}\n",
        "# layers = ['last_layer.weight', 'last_layer.bias']\n",
        "# for layer in layers:\n",
        "#   print(vgg16_fine_tune_last_layer.state_dict()[layer].shape)\n",
        "#   new_state_dict[layer] = vgg16_fine_tune_last_layer.state_dict()[layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyiH15Uz53ll"
      },
      "source": [
        "# for param_tensor in new_state_dict:\n",
        "#   print(param_tensor, \"\\t\", new_state_dict[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaEuGV8_7dqy"
      },
      "source": [
        "# ## loading the weights\n",
        "# checkpoint = torch.load(\"/content/drive/MyDrive/vgg16_with_normalisation_last_layer/checkpt8.pt\",map_location=torch.device(device))\n",
        "\n",
        "# new_state_dict = checkpoint['new_state_dict']\n",
        "# old_dict = vgg16_fine_tune_last_layer.state_dict()\n",
        "# layers = ['last_layer.0.weight', 'last_layer.0.bias', 'last_layer.2.weight', 'last_layer.2.bias', 'last_layer.4.weight', 'last_layer.4.bias']\n",
        "# for layer in layers:\n",
        "#   old_dict[layer] = new_state_dict[layer] \n",
        "# vgg16_fine_tune_last_layer.load_state_dict(old_dict)\n",
        "\n",
        "\n",
        "# #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# vgg16_fine_tune_last_layer.train()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6qba5XJ6Oc9"
      },
      "source": [
        "## we will save and load this dictionary only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozk7oJn03QVJ"
      },
      "source": [
        "def accuracy(x, targets):\n",
        "  # receive the outputs of linear layer\n",
        "  # first apply softmax then take argmax to know the index\n",
        "  # then compare\n",
        "  # input will be (batch_size, )\n",
        "  probs = nn.functional.softmax(x)\n",
        "  labels = torch.argmax(probs, dim=1)\n",
        "\n",
        "  count=0\n",
        "  for label, target in zip(labels, targets):\n",
        "    #print(label, target)\n",
        "    if(label.item() == target.item()):\n",
        "      count+=1\n",
        "  \n",
        "  return count/labels.shape[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ahmi8ktVOps"
      },
      "source": [
        "# temp = torch.randn(2,1,227,227)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2savO4vVf7f"
      },
      "source": [
        "# _mean = temp[:,0,:,:].mean(axis=0)\n",
        "# print(_mean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG_LtihfD8Dq"
      },
      "source": [
        "class MetaClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MetaClassifier, self).__init__()\n",
        "\n",
        "    ## five output of (batch_size, 16)\n",
        "    self.meta_classifier = nn.Sequential(nn.Linear(16*5, 40),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(40,16))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.meta_classifier(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi6ThQhmK_Ad"
      },
      "source": [
        "meta_classifier = MetaClassifier().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThwvgOfhtjTc"
      },
      "source": [
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, meta_classifier.parameters()), \n",
        "                             lr=lr, betas=(b1, b2))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIN9mFf8IG4F"
      },
      "source": [
        "# left = torch.load('/content/drive/MyDrive/resnet18_left_features/train/0.pt', map_location=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3NqX3DjIVq9",
        "outputId": "c2ecde75-1b2c-4484-f2ef-420dc3bd77fd"
      },
      "source": [
        "# print(left.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0vWJkoL2RV",
        "outputId": "61188253-0ada-421c-f1fe-610a5faac735"
      },
      "source": [
        "# load weights of holistic model\n",
        "## load the weights till epoch 9\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/resnet18_fine_tune_all_four_blocks/checkpt8.pt\",map_location=torch.device(device))\n",
        "resnet18_fine_tune.load_state_dict(checkpoint['resnet18_fine_tune'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxvcQ1amMKRE"
      },
      "source": [
        "for (name, param) in (list(resnet18_fine_tune.named_parameters())):\n",
        "      param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzl0vdyuMpTl",
        "outputId": "9f0548d3-9d77-44d2-ae59-d5f2c2b353ce"
      },
      "source": [
        "for name, param in meta_classifier.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meta_classifier.0.weight\n",
            "meta_classifier.0.bias\n",
            "meta_classifier.2.weight\n",
            "meta_classifier.2.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtmuVi0MNCVU"
      },
      "source": [
        "for name, param in resnet18_fine_tune.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547,
          "referenced_widgets": [
            "ab7440272a15446f81a870097be4718c",
            "a63347d949464fd9ba59b5b628096f53",
            "3bc38da7fd834036a4e0b12a52dcee0e",
            "adf22586a90440f98ce93f16bff72245",
            "35962889f1934b629707555504825ad8",
            "27cd128d659c49c1865f4ea3c6d21fbb",
            "b4644ba42b01418486d913a35d659e3f",
            "2f0fe76b3a36427880d3658e308205fb",
            "869f7d3ada6546cfaab751f1cf6560be",
            "aee35de1d9124cb0aa66fe1fe69c3307",
            "96bc31713c094b8884bab2fcea70e634",
            "8f0e4b3bd4754796b4cfe7ae5681cd2a",
            "98d7c224f1b640a0b17910c797be1ddb",
            "58a2ae5d137c4772a811738c28ada9b7",
            "e4227606809841db87a8c3c3aa394054",
            "b1bb9161f3494c93a5232e608b17de0d",
            "2b382454affe45f7a9262c19508b52e4",
            "5b0dab2bd3b749a583a07441df1915e1",
            "c44059739a22480fbaec5db0c0322a84",
            "c31c3044b3a7433c8f97c38e7d97b688",
            "87f941215e3744ae95d465ec0db078d0",
            "4e1a54fae66f4a35abfbb39df4acb1bc",
            "9ada235edebd4158a43be4327df12304",
            "e17fbb2165434a1f833f5f044261b28a",
            "925f41c2278a4a1ea71d80da1c3b62b3",
            "54a7b7807d5f4b8c8f4ccfb96bd3b263",
            "a24d974412934d19be092f577e6af5c1",
            "6f10e86b6dd04e7bb2554385f427ff10",
            "008d0e4cc2344661b00accc86526e4a8",
            "3bf5b56410cb4738b0ec6a259aba42e2",
            "29897fa983524e62bb088f15ca2b8f12",
            "e64028a233de4d4da602e02cac05b010",
            "709c22c228f944db91fc9ca5d24d2a68",
            "bfc0dad08ea74ee9a6c7eda3a0010318",
            "710e92b7d8f34a34a779534b32a3a751",
            "f64a27dee25c4392815afa70f9745b36",
            "18455f2361c74ea882c86995e3bd54c4",
            "76432bec6b834046a1bb3cad885f90b4",
            "27f1f6b6b9bc40f4b091d3e8f4fd6ec2",
            "cb7334f112d04666a814e9f8e4f220ce",
            "88dbbab7039042ebbd1c518bcfd106a5",
            "4de1b86943c343bc8049b9850787ab20"
          ]
        },
        "id": "97S8TtiXPdmD",
        "outputId": "8164a45c-9f4f-49e4-b067-b9a2c879adb2"
      },
      "source": [
        "train_losses, test_losses = [], []\n",
        "train_acc, test_acc = [], []\n",
        "test_counter = [idx*len(test_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "train_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "\n",
        "n_epochs = 24\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  # Training loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(train_dataloader, desc=f'Training Epoch {epoch} ', total=int(len(train_dataloader)))\n",
        "  #no_of_batches = len(tqdm)\n",
        "  #print(no_of_batches)\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "    if(batch_idx >= 2123):\n",
        "      continue\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    meta_classifier.train();\n",
        "\n",
        "    # for key in imgs:\n",
        "    #   imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic'].to(device)\n",
        "    targets = imgs['targets'].to(device)\n",
        "    left_pred = torch.load(f'/content/drive/MyDrive/resnet18_left_features/train/{epoch}.pt', map_location=device)\n",
        "    right_pred = torch.load(f'/content/drive/MyDrive/resnet18_right_features/train/{epoch}.pt', map_location=device)\n",
        "    header_pred = torch.load(f'/content/drive/MyDrive/resnet18_header_features/train/{epoch}.pt', map_location=device)\n",
        "    footer_pred = torch.load(f'/content/drive/MyDrive/resnet18_footer_features/train/{epoch}.pt', map_location=device)\n",
        "    holistic_prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    #prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    concatenated_pred = torch.cat((left_pred, right_pred, header_pred, footer_pred, holistic_prediction), dim=1)\n",
        "\n",
        "    final_pred = meta_classifier(concatenated_pred)\n",
        "\n",
        "    loss_calc = criterion(final_pred.to(device), targets.to(device))\n",
        "\n",
        "    loss_calc.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(final_pred.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  train_losses.append(loss/len(train_dataloader)) ## divided by total number of batches\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  ## Testing loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n",
        "\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "\n",
        "    meta_classifier.eval;\n",
        "\n",
        "    if(batch_idx >= 2123):\n",
        "      continue\n",
        "    # for key in imgs:\n",
        "    #   imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic'].to(device)\n",
        "    targets = imgs['targets'].to(device)\n",
        "    left_pred = torch.load(f'/content/drive/MyDrive/resnet18_left_features/test/{epoch}.pt', map_location=device)\n",
        "    right_pred = torch.load(f'/content/drive/MyDrive/resnet18_right_features/test/{epoch}.pt', map_location=device)\n",
        "    header_pred = torch.load(f'/content/drive/MyDrive/resnet18_header_features/test/{epoch}.pt', map_location=device)\n",
        "    footer_pred = torch.load(f'/content/drive/MyDrive/resnet18_footer_features/test/{epoch}.pt', map_location=device)\n",
        "    holistic_prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    #prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    concatenated_pred = torch.cat((left_pred, right_pred, header_pred, footer_pred, holistic_prediction), dim=1)\n",
        "\n",
        "    final_pred = meta_classifier(concatenated_pred)\n",
        "\n",
        "    loss_calc = criterion(final_pred.to(device), targets.to(device))\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(final_pred.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  test_losses.append(loss/len(test_dataloader)) ## divided by total number of batches\n",
        "\n",
        "  if(True):\n",
        "    torch.save({\n",
        "          \n",
        "          'meta_classifier' : meta_classifier.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'train_loss' : train_losses[-1],\n",
        "          'test_loss' : test_losses[-1],\n",
        "          'epoch': epoch+1,\n",
        "          }, f\"/content/drive/MyDrive/resnet18_ensemble/checkpt{epoch+1}.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab7440272a15446f81a870097be4718c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 0 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "869f7d3ada6546cfaab751f1cf6560be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 0 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b382454affe45f7a9262c19508b52e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 1 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "925f41c2278a4a1ea71d80da1c3b62b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 1 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "709c22c228f944db91fc9ca5d24d2a68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 2 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88dbbab7039042ebbd1c518bcfd106a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 2 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4de1b86943c343bc8049b9850787ab20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 3 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-e5521bbd4c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#no_of_batches = len(tqdm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m#print(no_of_batches)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7wXdfQrGSvF"
      },
      "source": [
        "## load the weights till epoch 2\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/resnet18_ensemble/checkpt3.pt\",map_location=torch.device(device))\n",
        "meta_classifier.load_state_dict(checkpoint['meta_classifier'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "626c6b71383349a996cbbaca98400fe4",
            "bf9a5f9046cd425489d776ec8809cfd0",
            "1fb939685ef64dd394210e86a723fbf2",
            "b40ab27381cb44ce9072cac644979fcc",
            "c7cb27fee07041759813e1204ec484e7",
            "e68967a233c44336ae66088331a822d0",
            "1f2767445fc04d8d9f9c7e9563b4d6ac",
            "3835f1a98d6a4efcb7bd31044afb6671",
            "72187261edbe4f169c2c1289d2a347ee",
            "59e125881712448bb52d622049f5f9ce",
            "9938a8c321bf40c4aaa52fcb6194ce33",
            "c04659c984374d86a19dcb3774d7ab2d",
            "2217e4ea14204171aa224d984be82631",
            "9d8570da18734bdb9401cd616414a9ff",
            "25b4907e860d4a1984e08057cbfbb509",
            "df0beb01c6ec468893891f7fbd78f781",
            "94b9b9ff04884bb18ae3ca1ff9bf138b",
            "93e4bf0ba8514314b9937a89df6a8243",
            "4915c4710c5a49dba21b0a69d26a1024",
            "79167de76455413e801ef71d8f8283c8",
            "b9a557975e05458c98f3e0b22a5fffc2",
            "c6962cd238db4088aab68167746350d8",
            "0adf8cd991c74335bfe9bef9a568b241",
            "4155e93935124c72887b907b34a683c3",
            "4ecb20b7194744c4bc4f658c981ccda2",
            "af4c522f09b84f829f30eae397227efd",
            "96f497b16ec14dc0ae3424411e2c28b7",
            "e3c99cc44b9849c9a26be02f7c24e031",
            "789353319e25494ba370c2bc105dbd84",
            "175415b3ad3b475c92814c7ca99c525f",
            "cebd4cd0b71d43ccb9a48576d7a6f734",
            "c1d48a6bd15f476295fbb758f15bf7bf",
            "1b99d006e8bc4465951524aeaa5924dd",
            "0653db0a0ff24395b84f72be54055688",
            "63bda01710a64cf3bb2011835ab38377",
            "09ab36f2c4c54fd2bdfefc9cc8f28756",
            "1af0068c56d24cb183fe72de14d303dc",
            "766861f2b87e45568249e67801074405",
            "bae38103b4d445c08932125b24df255c",
            "543fbd67975540dca3bca5f16e8d0f94",
            "295b3639cd8040fdb976c407c63d2033",
            "fce3735b90fd41728a4726da6817d281"
          ]
        },
        "id": "JjemNBEjC1wl",
        "outputId": "a4de90cc-81e2-4bf5-a28d-81e58a7ff533"
      },
      "source": [
        "train_losses, test_losses = [], []\n",
        "train_acc, test_acc = [], []\n",
        "test_counter = [idx*len(test_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "train_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "\n",
        "n_epochs = 24\n",
        "for epoch in range(3,n_epochs):\n",
        "  \n",
        "  # Training loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(train_dataloader, desc=f'Training Epoch {epoch} ', total=int(len(train_dataloader)))\n",
        "  #no_of_batches = len(tqdm)\n",
        "  #print(no_of_batches)\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "    if(batch_idx >= 2123):\n",
        "      continue\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    meta_classifier.train();\n",
        "\n",
        "    # for key in imgs:\n",
        "    #   imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic'].to(device)\n",
        "    targets = imgs['targets'].to(device)\n",
        "    left_pred = torch.load(f'/content/drive/MyDrive/resnet18_left_features/train/{epoch}.pt', map_location=device)\n",
        "    right_pred = torch.load(f'/content/drive/MyDrive/resnet18_right_features/train/{epoch}.pt', map_location=device)\n",
        "    header_pred = torch.load(f'/content/drive/MyDrive/resnet18_header_features/train/{epoch}.pt', map_location=device)\n",
        "    footer_pred = torch.load(f'/content/drive/MyDrive/resnet18_footer_features/train/{epoch}.pt', map_location=device)\n",
        "    holistic_prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    #prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    concatenated_pred = torch.cat((left_pred, right_pred, header_pred, footer_pred, holistic_prediction), dim=1)\n",
        "\n",
        "    final_pred = meta_classifier(concatenated_pred)\n",
        "\n",
        "    loss_calc = criterion(final_pred.to(device), targets.to(device))\n",
        "\n",
        "    loss_calc.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(final_pred.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  train_losses.append(loss/len(train_dataloader)) ## divided by total number of batches\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  ## Testing loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n",
        "\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "\n",
        "    meta_classifier.eval;\n",
        "\n",
        "    if(batch_idx >= 2123):\n",
        "      continue\n",
        "    # for key in imgs:\n",
        "    #   imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic'].to(device)\n",
        "    targets = imgs['targets'].to(device)\n",
        "    left_pred = torch.load(f'/content/drive/MyDrive/resnet18_left_features/test/{epoch}.pt', map_location=device)\n",
        "    right_pred = torch.load(f'/content/drive/MyDrive/resnet18_right_features/test/{epoch}.pt', map_location=device)\n",
        "    header_pred = torch.load(f'/content/drive/MyDrive/resnet18_header_features/test/{epoch}.pt', map_location=device)\n",
        "    footer_pred = torch.load(f'/content/drive/MyDrive/resnet18_footer_features/test/{epoch}.pt', map_location=device)\n",
        "    holistic_prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    #prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    concatenated_pred = torch.cat((left_pred, right_pred, header_pred, footer_pred, holistic_prediction), dim=1)\n",
        "\n",
        "    final_pred = meta_classifier(concatenated_pred)\n",
        "\n",
        "    loss_calc = criterion(final_pred.to(device), targets.to(device))\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(final_pred.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  test_losses.append(loss/len(test_dataloader)) ## divided by total number of batches\n",
        "\n",
        "  if(True):\n",
        "    torch.save({\n",
        "          \n",
        "          'meta_classifier' : meta_classifier.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'train_loss' : train_losses[-1],\n",
        "          'test_loss' : test_losses[-1],\n",
        "          'epoch': epoch+1,\n",
        "          }, f\"/content/drive/MyDrive/resnet18_ensemble/checkpt{epoch+1}.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "626c6b71383349a996cbbaca98400fe4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 3 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72187261edbe4f169c2c1289d2a347ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 3 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94b9b9ff04884bb18ae3ca1ff9bf138b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 4 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ecb20b7194744c4bc4f658c981ccda2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 4 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b99d006e8bc4465951524aeaa5924dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 5 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "295b3639cd8040fdb976c407c63d2033",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 5 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce3735b90fd41728a4726da6817d281",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training Epoch 6 ', max=2125.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-e82918187451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_calc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtqdm_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WJE5XkKO6kU"
      },
      "source": [
        "# train_paths, test_paths = train_test_split(train_path, test_size=0.1, random_state=42)\n",
        "# #train_paths = train_paths[:len(train_paths)]\n",
        "# test_paths = test_paths[:len(test_paths)]\n",
        "\n",
        "# #train_dataloader = DataLoader(ImageDataset(train_paths), batch_size=batch_size, shuffle=True, num_workers=n_cpu)\n",
        "# test_dataloader = DataLoader(ImageDataset(test_paths), batch_size=int(batch_size), shuffle=True, num_workers=n_cpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "41c38bac18354a3fa0410925b54f698a",
            "6e0335b61674413fa05d672fef56c13c",
            "8314d667a57f4509ba5d40db381dec1d",
            "75a3aacbe1e54dad9236cd67ee63288a",
            "7fd6ba1457e34e24bdfb9d7e43ee4e22",
            "4e11a15118bd4bfc9e8c56ee30557ff0",
            "b4a2fe66af774861a04d3a439f30fa53",
            "2239422181d74785b824b1eb099e5c27"
          ]
        },
        "id": "I7z3c-_yEXWy",
        "outputId": "24c2cf8b-2959-46a0-ff76-a5cad750d66f"
      },
      "source": [
        "######## Evaluation loop\n",
        "train_losses, test_losses = [], []\n",
        "train_acc, test_acc = [], []\n",
        "test_counter = [idx*len(test_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "train_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "\n",
        "n_epochs = 1\n",
        "for epoch in range(n_epochs):\n",
        "  ## Testing loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n",
        "\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "\n",
        "    meta_classifier.eval;\n",
        "\n",
        "    if(batch_idx >= 2123):\n",
        "      continue\n",
        "    # for key in imgs:\n",
        "    #   imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic'].to(device)\n",
        "    targets = imgs['targets'].to(device)\n",
        "    left_pred = torch.load(f'/content/drive/MyDrive/resnet18_left_features/test/{epoch}.pt', map_location=device)\n",
        "    right_pred = torch.load(f'/content/drive/MyDrive/resnet18_right_features/test/{epoch}.pt', map_location=device)\n",
        "    header_pred = torch.load(f'/content/drive/MyDrive/resnet18_header_features/test/{epoch}.pt', map_location=device)\n",
        "    footer_pred = torch.load(f'/content/drive/MyDrive/resnet18_footer_features/test/{epoch}.pt', map_location=device)\n",
        "    holistic_prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    #prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    concatenated_pred = torch.cat((left_pred, right_pred, header_pred, footer_pred, holistic_prediction), dim=1)\n",
        "\n",
        "    final_pred = meta_classifier(concatenated_pred)\n",
        "\n",
        "    loss_calc = criterion(final_pred.to(device), targets.to(device))\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(final_pred.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  test_losses.append(loss/len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41c38bac18354a3fa0410925b54f698a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 0 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxrgpX5K_Kwl"
      },
      "source": [
        "### the above result was obtained after 2 full epochs while the third epoch stopped in between."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "35b52cb521ed49d4bcf70c557c0611a5",
            "e24fe7b751de4c40a1fe6e4be1bc888f",
            "dbe8e42d50b74ff0a98fb3b619cb7aab",
            "45563ed03d584fc0817866d274d1cc43",
            "661b4b727c2b48279438c07b3f85ff98",
            "d59fe89fd1464757b0977156fc6ad52b",
            "82f61a4c1f224489bff9555d6f12de35",
            "b7f2b9a17a6f415ba2d7627a3e536b8d"
          ]
        },
        "id": "Yu79XJ_vQnGO",
        "outputId": "8c9ea4a6-0af1-4929-da91-73f46704dd97"
      },
      "source": [
        "######## Evaluation loop\n",
        "train_losses, test_losses = [], []\n",
        "train_acc, test_acc = [], []\n",
        "test_counter = [idx*len(test_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "train_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n",
        "\n",
        "n_epochs = 1\n",
        "for epoch in range(n_epochs):\n",
        "  ## Testing loop\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n",
        "\n",
        "  for batch_idx, imgs in enumerate(tqdm_bar):\n",
        "\n",
        "    meta_classifier.eval;\n",
        "\n",
        "    if(batch_idx >= 2123):\n",
        "      continue\n",
        "    # for key in imgs:\n",
        "    #   imgs[key] = imgs[key].to(device)\n",
        "\n",
        "    holistic_img = imgs['holistic'].to(device)\n",
        "    targets = imgs['targets'].to(device)\n",
        "    left_pred = torch.load(f'/content/drive/MyDrive/resnet18_left_features/test/{epoch}.pt', map_location=device)\n",
        "    right_pred = torch.load(f'/content/drive/MyDrive/resnet18_right_features/test/{epoch}.pt', map_location=device)\n",
        "    header_pred = torch.load(f'/content/drive/MyDrive/resnet18_header_features/test/{epoch}.pt', map_location=device)\n",
        "    footer_pred = torch.load(f'/content/drive/MyDrive/resnet18_footer_features/test/{epoch}.pt', map_location=device)\n",
        "    holistic_prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    #prediction = resnet18_fine_tune(holistic_img.to(device))\n",
        "\n",
        "    concatenated_pred = torch.cat((left_pred, right_pred, header_pred, footer_pred, holistic_prediction), dim=1)\n",
        "\n",
        "    final_pred = meta_classifier(concatenated_pred)\n",
        "\n",
        "    loss_calc = criterion(final_pred.to(device), targets.to(device))\n",
        "\n",
        "    loss += loss_calc.item()\n",
        "    acc += accuracy(final_pred.to(device), targets.to(device))\n",
        "    tqdm_bar.set_postfix(loss=loss/(batch_idx+1), acc = acc/(batch_idx+1))\n",
        "\n",
        "  test_losses.append(loss/len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b52cb521ed49d4bcf70c557c0611a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing Epoch 0 ', max=375.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CALu7RiQn1K"
      },
      "source": [
        "## above code after completing 5 full epochs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}